{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchtune\n",
    "from model.model import SeqFTTransformer\n",
    "from model.loader import get_loaders\n",
    "from utils import get_pck_key_size, get_pck_value_size\n",
    "import math\n",
    "import multiprocessing as mp\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "mp.set_start_method('spawn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cont = 25 # Number of continuous features\n",
    "#TODO: should be set automatically\n",
    "\n",
    "# Detect device\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "batch_size = 16\n",
    "kv_caching = False\n",
    "num_workers = 1\n",
    "\n",
    "shift_cols = [\n",
    "    'events',\n",
    "    'description',\n",
    "    'hit_location',\n",
    "    'bb_type',\n",
    "    'pfx_x',\n",
    "    'pfx_z',\n",
    "    'hc_x',\n",
    "    'hc_y',\n",
    "    'vx0',\n",
    "    'vy0',\n",
    "    'vz0',\n",
    "    'ax',\n",
    "    'ay',\n",
    "    'az',\n",
    "    'hit_distance_sc',\n",
    "    'launch_speed',\n",
    "    'launch_angle',\n",
    "    'release_speed',\n",
    "    'release_spin_rate',\n",
    "    'release_extension',\n",
    "    'release_pos_x',\n",
    "    'release_pos_y',\n",
    "    'release_pos_z',\n",
    "    'spin_axis',\n",
    "]\n",
    "\n",
    "train_loader, val_loader, test_loader = get_loaders(\n",
    "    'full_multi/data/1623_full_cleandata_bin.parquet',\n",
    "    'full_multi/data/train_full_1623.pkl',\n",
    "    'full_multi/data/val_full_1623.pkl',\n",
    "    'full_multi/data/test_full_1623.pkl',\n",
    "    'full_multi/mappings/pn_to_pn.pkl',\n",
    "    num_cont=num_cont,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    columns_to_shift=shift_cols\n",
    "    )\n",
    "\n",
    "comb_map_files = [\n",
    "    'full_multi/mappings/stand.pkl',\n",
    "    'full_multi/mappings/p_throws.pkl',\n",
    "    'full_multi/mappings/game_year.pkl',\n",
    "    'full_multi/mappings/balls.pkl',\n",
    "    'full_multi/mappings/strikes.pkl',\n",
    "    'full_multi/mappings/on_3b.pkl',\n",
    "    'full_multi/mappings/on_2b.pkl',\n",
    "    'full_multi/mappings/on_1b.pkl',\n",
    "    'full_multi/mappings/outs_when_up.pkl',\n",
    "    'full_multi/mappings/inning_topbot.pkl',\n",
    "    'full_multi/mappings/events.pkl',\n",
    "    'full_multi/mappings/description.pkl',\n",
    "    'full_multi/mappings/home_team.pkl',\n",
    "    'full_multi/mappings/away_team.pkl', \n",
    "    'full_multi/mappings/hit_location.pkl',\n",
    "    'full_multi/mappings/bb_type.pkl',\n",
    "]\n",
    "\n",
    "sep_map_files = [\n",
    "    'full_multi/mappings/batter.pkl',\n",
    "    'full_multi/mappings/pitcher.pkl',\n",
    "    'full_multi/mappings/fielder_2.pkl',\n",
    "]\n",
    "\n",
    "comb_cat_sizes = tuple([get_pck_key_size(map_file) for map_file in comb_map_files])\n",
    "\n",
    "sep_cat_sizes = tuple([get_pck_key_size(map_file) for map_file in sep_map_files])\n",
    "\n",
    "sep_cat_emb_dims = tuple([4] * len(sep_cat_sizes))\n",
    "\n",
    "tgt_cat_size = get_pck_key_size('full_multi/mappings/pn_to_pn.pkl')\n",
    "\n",
    "out_cat_size = get_pck_value_size('full_multi/mappings/pn_to_pn.pkl')\n",
    "\n",
    "model_config = {\n",
    "    'comb_category_sizes' : comb_cat_sizes,\n",
    "    'comb_category_emb_dim' : 8,\n",
    "    'sep_category_sizes' : sep_cat_sizes,\n",
    "    'sep_category_emb_dims' : sep_cat_emb_dims,\n",
    "    'pad_idx' : 0,\n",
    "    'num_continuous' : num_cont,\n",
    "    'dim' : 32,\n",
    "    'depth' : 1,\n",
    "    'num_heads' : 8,\n",
    "    'num_kv_heads' : 4,\n",
    "    'tgt_categories' : tgt_cat_size,\n",
    "    'max_seq_len' : 128,\n",
    "    'max_batch_size' : batch_size,\n",
    "    'out_categories' : out_cat_size,\n",
    "    'kv_caching' : kv_caching,\n",
    "    'attn_dropout' : 0.1,\n",
    "    'hidden_mult' : 2\n",
    "}\n",
    "with open('trained_models/model_config.pkl', 'wb') as f:\n",
    "    pickle.dump(model_config, f)\n",
    "\n",
    "model = SeqFTTransformer(\n",
    "    comb_category_sizes=model_config['comb_category_sizes'],\n",
    "    comb_category_emb_dim=model_config['comb_category_emb_dim'],\n",
    "    sep_category_sizes=model_config['sep_category_sizes'],\n",
    "    sep_category_emb_dims=model_config['sep_category_emb_dims'],\n",
    "    pad_idx=model_config['pad_idx'],\n",
    "    num_continuous=model_config['num_continuous'],\n",
    "    dim=model_config['dim'],\n",
    "    depth=model_config['depth'],\n",
    "    num_heads=model_config['num_heads'],\n",
    "    num_kv_heads=model_config['num_kv_heads'],\n",
    "    tgt_categories=model_config['tgt_categories'],\n",
    "    max_seq_len=model_config['max_seq_len'],\n",
    "    max_batch_size=model_config['max_batch_size'],\n",
    "    out_categories=model_config['out_categories'],\n",
    "    kv_caching=model_config['kv_caching'],\n",
    "    attn_dropout=model_config['attn_dropout'],\n",
    "    hidden_mult=model_config['hidden_mult']\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define training\n",
    "def train(model, train_loader, criterion, optimizer, scheduler, device):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "\n",
    "    for bs, ps, cs, cas, cos, ts, res in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        bs = bs.to(device)\n",
    "        ps = ps.to(device)\n",
    "        cs = cs.to(device)\n",
    "        cas = cas.to(device)\n",
    "        cos = cos.to(device)\n",
    "        ts = ts.to(device)\n",
    "        tgt = F.pad(ts[:, :-1], (1, 0), value=0)\n",
    "        res = res.to(device)\n",
    "        \n",
    "        out = model(\n",
    "            cas,\n",
    "            torch.cat((bs.unsqueeze(2),ps.unsqueeze(2), cs.unsqueeze(2)),dim=2),\n",
    "            cos,\n",
    "            tgt\n",
    "        )\n",
    "        \n",
    "        loss = criterion(out.transpose(2,1), res.to(dtype=torch.long))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        train_loss += loss.item()\n",
    "    return train_loss / len(train_loader)\n",
    "\n",
    "\n",
    "def val(model, val_loader, criterion, mask_const, device):\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        total_loss = 0\n",
    "        total_acc = 0\n",
    "\n",
    "        for bs, ps, cs, cas, cos, ts, res in val_loader:\n",
    "            bs = bs.to(device)\n",
    "            ps = ps.to(device)\n",
    "            cs = cs.to(device)\n",
    "            cas = cas.to(device)\n",
    "            cos = cos.to(device)\n",
    "            ts = ts.to(device)\n",
    "            tgt = F.pad(ts[:, :-1], (1, 0), value=0)\n",
    "            res = res.to(device)\n",
    "            \n",
    "            out = model(\n",
    "                cas,\n",
    "                torch.cat((bs.unsqueeze(2),ps.unsqueeze(2), cs.unsqueeze(2)),dim=2),\n",
    "                cos,\n",
    "                tgt\n",
    "            )\n",
    "            \n",
    "            loss = criterion(out.transpose(2,1), res.to(dtype=torch.long))\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # Calculate accuracy\n",
    "            preds = out.argmax(dim=2)\n",
    "\n",
    "            accuracy = (preds == res).where(res != mask_const, torch.zeros(preds.size(), device=device)).sum().item() / (res != mask_const).sum().item()\n",
    "            total_acc += accuracy\n",
    "        return total_loss / len(val_loader), total_acc /len(val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter('runs/model_visualization')\n",
    "ts = ts.to(torch.int64).to(device)\n",
    "writer.add_graph(model, (torch.cat((bs.unsqueeze(2),ps.unsqueeze(2),cas),dim=2).squeeze(0),\n",
    "    cos.squeeze(0)))\n",
    "writer.close()  \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model hyperparameters\n",
    "loss_func = nn.CrossEntropyLoss\n",
    "learning_rate = 2e-5\n",
    "opt_func = torch.optim.AdamW\n",
    "epochs = 15\n",
    "mask_const = 0\n",
    "\n",
    "\n",
    "optimizer = opt_func(model.parameters(), lr=learning_rate)\n",
    "criterion = loss_func(ignore_index=mask_const)\n",
    "\n",
    "# Scheduling\n",
    "num_train_samples = len(train_loader)\n",
    "warmup_ratio = 0.1\n",
    "total_steps = (num_train_samples // batch_size) * epochs\n",
    "warmup_steps = int(total_steps * warmup_ratio)\n",
    "scheduler = torchtune.training.get_cosine_schedule_with_warmup(optimizer, warmup_steps, total_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_float32_matmul_precision('high')\n",
    "\n",
    "opt_train = torch.compile(train)\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "# TRAIN LOOP\n",
    "for epoch in range(epochs):\n",
    "    train_loss = opt_train(model, train_loader, criterion, optimizer, scheduler, device)\n",
    "    #train_loss = train(model, train_loader, criterion, optimizer, scheduler, device)\n",
    "\n",
    "    if kv_caching:\n",
    "        model.reset_caches()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    val_loss, _ = val(model, val_loader, criterion, mask_const, device)\n",
    "\n",
    "    if kv_caching:\n",
    "        model.reset_caches()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "\n",
    "    print(f'Epoch: {epoch+1:02}')\n",
    "    print(f'\\tTrain Loss: {train_loss:.4f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
    "    print(f'\\t Val Loss: {val_loss:.4f} |  Val. PPL: {math.exp(val_loss):7.3f}')\n",
    "\n",
    "    best_val_loss = None\n",
    "\n",
    "    if not best_val_loss or val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save(model.state_dict(), 'trained_models/new_sft_full_1623.pth')\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(train_losses, label='Train Loss')\n",
    "    plt.plot(val_losses, label='Val Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# test the best model\n",
    "test_loss, test_acc = val(model, test_loader, criterion, mask_const, device)\n",
    "print(f'\\t Test Loss: {test_loss:.4f} |  Test Acc.: {test_acc:7.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = val(model, test_loader, criterion, mask_const, device)\n",
    "print(f'\\t Test Loss: {test_loss:.4f} |  Test Acc.: {test_acc:7.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
